{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LetsHaveAConvo.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "bzY9nK-_LLC6",
        "Ppacy9UTzAJT",
        "asIjm01UzUiK",
        "tnva-KuHjLw0",
        "TbZq-vUT-hgd",
        "Po6px0oM-vdg",
        "huruvZgbDXb_",
        "mLDD3Iy5D-UB",
        "phnTXhesOdtT",
        "NLR2O6j3F6k-",
        "SPtsnJscR-oA",
        "kqD61qqNOqWa",
        "vEn4dyybOzy4",
        "Zu8T1uCEakHJ",
        "OTd7QtwwEEvt",
        "-IidJOUgbNGF",
        "SrVGalGatWaK",
        "qwubzWGWWD6E"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/errai34/GettingStarted/blob/master/LetsHaveAConvo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "_Dyw4pbps6_9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Install packages on the back end"
      ]
    },
    {
      "metadata": {
        "id": "_e3IFLX-ogPt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# install software on the backend, which is located at \n",
        "# Google's Super Secret Sky Server in an alternate universe.\n",
        "# The backend is called a 'hosted runtime' if it is on their server.\n",
        "# A local runtime would start a colab notebook on your machine locally. \n",
        "# Think of google colab as a Google Docs version of Jupyter Notebooks\n",
        "\n",
        "# remove display of install details\n",
        "%%capture --no-display \n",
        "\n",
        "# pip install\n",
        "!pip install numpy matplotlib scipy pandas scikit-learn astropy seaborn ipython jupyter #standard install for DSFP\n",
        "!pip install keras tensorflow  # required for deep learning \n",
        "!pip install pycm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JYuP1qqMpyHZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# standard-ish imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import itertools\n",
        "\n",
        "# non-standard, but stable package for confusion matrices\n",
        "from pycm import ConfusionMatrix\n",
        "\n",
        "\n",
        "# neural network / machine learning packages\n",
        "from sklearn import metrics\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6U46EXbasNvb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Networks make the future now!\n",
        "\n",
        "**Learning Objectives**\n",
        "\n",
        "\n",
        "1.  Gain familiarity with \n",
        "      1.   Two standard convolutional neural network (CNN) architectures: \n",
        "           1. **Feed-forward CNN**\n",
        "           2. **Convolutional Autoencoder (CAE)**\n",
        "      2.   One standard task performed with CNNs: **Binary Classification**\n",
        "      3.   One new diagnostic of CNNs: **Feature maps from the first layer**\n",
        "2.  Experience fundamental considerations, pitfalls, and strategies when training NNs\n",
        "      1.   Data set preparation (never underestimate the time required for this)\n",
        "      2.   CNN layer manipulation and architecture design\n",
        "      5.   Model fitting (the learning process)\n",
        "      6.   Effects of image quality\n",
        "3.  Apply diagnostics from previous exercises\n",
        "4.  Apply new diagnostics: look inside the networks with feature maps of the first layer\n",
        "5.  Continue connecting NN functionality to data set structure and problem of interest\n",
        "\n",
        "\n",
        "Some of this notebook is very similar to the first one, but we're using a new architecture that has more moving pieces.\n",
        "\n",
        "\n",
        "\n",
        "*I'm still taking bets that we can start a paper with deep nets during the Saturday hack.*\n"
      ]
    },
    {
      "metadata": {
        "id": "QNzZZiHZwvI7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Activity 1: Classify Handwritten Digits with Convolutional Neural Networks (CNNs)\n",
        "Is it a \"zero\" [0] or a \"one\" [1]?   (ooooh, the suspense; or maybe the suspense has dissipated by now.)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "bzY9nK-_LLC6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare the Data"
      ]
    },
    {
      "metadata": {
        "id": "Ppacy9UTzAJT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Download the data \n",
        "(ooh look it's all stored on Amazon's AWS!)\n",
        "(pssst, we're in the cloooud)"
      ]
    },
    {
      "metadata": {
        "id": "qwXuui6_yYBv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import MNIST data\n",
        "(x_train_temp, y_train_temp), (x_test_temp, y_test_temp) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "asIjm01UzUiK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### **Look** at the data\n",
        "(always do this so that you **know** what the structure is.)"
      ]
    },
    {
      "metadata": {
        "id": "5L507V2Ayk3y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Print the shapes\n",
        "print(\"Train Data Shape:\", x_train_temp.shape)\n",
        "print(\"Test Data Shape:\", x_test_temp.shape)\n",
        "print(\"Train Label Shape:\", y_train_temp.shape)\n",
        "print(\"Test Label Shape:\", y_test_temp.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SquIrP2E0Pnz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Do the shapes of 'data' and 'label' (for train and test, respectively) match? If they don't now, Keras/TF will kindly yell at you later.**\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "p9sOE3TI4nHR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Print an example\n",
        "print(\"Example:\")\n",
        "print(\"y_train[0] is the label for the 0th image, and it is a\", y_train_temp[0])\n",
        "print(\"x_train[0] is the image data, and you kind of see the pattern in the array of numbers\")\n",
        "print(x_train_temp[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FiBKC1_q4r34",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Can you see the pattern of the number in the array?** "
      ]
    },
    {
      "metadata": {
        "id": "kcUsjxeSz9aF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Plot the data! \n",
        "f = plt.figure()\n",
        "f.add_subplot(1,2, 1)\n",
        "plt.imshow(x_train_temp[0])\n",
        "f.add_subplot(1,2, 2)\n",
        "plt.imshow(x_train_temp[1])\n",
        "plt.show(block=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tnva-KuHjLw0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Prepare the data\n",
        "\n",
        "Data often need to be re-shaped and normalized for ingestion into the neural network."
      ]
    },
    {
      "metadata": {
        "id": "xPVp8HLR4LzC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Normalize the data\n",
        "\n",
        "The images are recast as float and normalized to one for the network.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "vTCyohBf4Nhp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"Before:\", np.min(x_train_temp), np.max(x_train_temp))\n",
        "x_train = x_train_temp.astype('float32')\n",
        "x_test = x_test_temp.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "y_train = y_train_temp\n",
        "y_test = y_test_temp\n",
        "print(\"After:\", np.min(x_train), np.max(x_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ashwVZDUAIJS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Reshape the data arrays: set the input shape to be ready for a convolution [NEW]\n",
        "\n",
        "We're going to use a Dense Neural Architecture, not as images, so we need to make the input shape appropriate."
      ]
    },
    {
      "metadata": {
        "id": "6zzzMHpk_OgP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# read the dimensions from one example in the training set\n",
        "img_rows, img_cols = x_train[0].shape[0], x_train[0].shape[1]\n",
        "\n",
        "# Different NN libraries (e.g., TF) use different ordering of dimensions\n",
        "# Here we set the \"input shape\" so that later the NN knows what shape to expect\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)  \n",
        "    input_shape = (img_rows, img_cols, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3aTWoi_E6Ueh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Apply *one-hot encoding* to the data\n",
        "\n",
        "\n",
        "1.   Current encoding provides a literal label. For example, the label for \"3\"  is *3*.\n",
        "2.   One-hot encoding places a \"1\" in an array at the appropriate location for that datum. For example, the label \"3\" becomes *[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]*\n",
        "\n",
        "This increases the efficiency of the matrix algebra during network training and evaluation.\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "GIWLxZN099Bl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# One-hot encoding\n",
        "num_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4PO2kozw-czq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Design Neural Network Architecture!"
      ]
    },
    {
      "metadata": {
        "id": "TbZq-vUT-hgd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Select model format"
      ]
    },
    {
      "metadata": {
        "id": "OAyMY-sG-bka",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Po6px0oM-vdg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Add layers to the model sequentially [NEW]"
      ]
    },
    {
      "metadata": {
        "id": "-apTS3Fyrc2B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TuK3wK307de0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*Things to think about and notice:*\n",
        "\n",
        "1. How does the \"output shape\" column change as you go through the network? How does this relate to pictures of CNNs you've seen (or might find on google images, for example)?\n",
        "2.  What happens when you re-compile the [cell where you add layers sequentially](https://colab.research.google.com/drive/1wKzhJ0cOsJbgM9L0uIVUCYW1f2Zdf3PK#scrollTo=qXiW9aIx9_CM&line=3&uniqifier=1), without first compiling model-definition cell. Why does that happen?"
      ]
    },
    {
      "metadata": {
        "id": "huruvZgbDXb_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Compile the model\n",
        "\n",
        "Select three key options\n",
        "1.   **optimizer**: the method for optimizing the weights. \"Stochastic Gradient Descent (SGD)\" is the canonical method.\n",
        "2.   **loss** function: the form of the function to encode the difference between the data's true label and the predict label.\n",
        "3.   **metric**: the function by which the model is evaluated."
      ]
    },
    {
      "metadata": {
        "id": "HLaQvODcBzi2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"sgd\", loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mLDD3Iy5D-UB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Fit (read: Train) the model"
      ]
    },
    {
      "metadata": {
        "id": "7Qu7XpVQFvvg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Training parameters\n",
        "batch_size = 32 # number of images per epoch\n",
        "num_epochs = 5 # number of epochs\n",
        "validation_split = 0.8 # fraction of the training set that is for validation only"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SYAh_2hODQTd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(x_train, y_train, \n",
        "                    batch_size=batch_size, \n",
        "                    epochs=num_epochs, \n",
        "                    validation_split=validation_split, \n",
        "                    verbose=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vzLU9LOF4srp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "*Things to think about and notice:*\n",
        "\n",
        "1. How fast is this training compared to the Dense/Fully Connected Networks? What could be a causing a difference between these two networks?\n",
        "2. Why is it taking a long time at the end of each epoch?\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "phnTXhesOdtT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Diagnostics!\n"
      ]
    },
    {
      "metadata": {
        "id": "NLR2O6j3F6k-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Evaluate overall model efficacy\n",
        "\n",
        "Evaluate model on training and test data and compare. This provides summary values that are equivalent to the final value in the accuracy/loss history plots."
      ]
    },
    {
      "metadata": {
        "id": "ZBKTaHUADR0p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loss_train, acc_train  = model.evaluate(x_train, y_train, verbose=False)\n",
        "loss_test, acc_test  = model.evaluate(x_test, y_test, verbose=False)\n",
        "print(f'Train acc/loss: {acc_train:.3}, {loss_train:.3}')\n",
        "print(f'Test acc/loss: {acc_test:.3}, {loss_test:.3}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SPtsnJscR-oA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Predict train and test data"
      ]
    },
    {
      "metadata": {
        "id": "OI7KWUnATIT2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred_train = model.predict(x_train, verbose=True)\n",
        "y_pred_test = model.predict(x_test,verbose=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kqD61qqNOqWa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Plot accuracy and loss as a function of epochs (equivalently training time)\n"
      ]
    },
    {
      "metadata": {
        "id": "hH7SJntRDTtB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# set up figure\n",
        "f = plt.figure(figsize=(12,5))\n",
        "f.add_subplot(1,2, 1)\n",
        "\n",
        "# plot accuracy as a function of epoch\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training', 'validation'], loc='best')\n",
        "\n",
        "# plot loss as a function of epoch\n",
        "f.add_subplot(1,2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training', 'validation'], loc='best')\n",
        "plt.show(block=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rYMPVXD1CPnD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "*Things to think about and notice:*\n",
        "\n",
        "1. How do these curve shapes compare to the initial dense network results?\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "vEn4dyybOzy4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Confusion Matrix"
      ]
    },
    {
      "metadata": {
        "id": "r9fvhucyOyol",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Function: Convert from categorical back to numerical value\n",
        "def convert_to_index(array_categorical):\n",
        "  array_index = [np.argmax(array_temp) for array_temp in array_categorical]\n",
        "  return array_index\n",
        "\n",
        "def plot_confusion_matrix(cm,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function modified to plots the ConfusionMatrix object.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \n",
        "    Code Reference : \n",
        "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "    \n",
        "    This script is derived from PyCM repository: https://github.com/sepandhaghighi/pycm\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    plt_cm = []\n",
        "    for i in cm.classes :\n",
        "        row=[]\n",
        "        for j in cm.classes:\n",
        "            row.append(cm.table[i][j])\n",
        "        plt_cm.append(row)\n",
        "    plt_cm = np.array(plt_cm)\n",
        "    if normalize:\n",
        "        plt_cm = plt_cm.astype('float') / plt_cm.sum(axis=1)[:, np.newaxis]     \n",
        "    plt.imshow(plt_cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(cm.classes))\n",
        "    plt.xticks(tick_marks, cm.classes, rotation=45)\n",
        "    plt.yticks(tick_marks, cm.classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = plt_cm.max() / 2.\n",
        "    for i, j in itertools.product(range(plt_cm.shape[0]), range(plt_cm.shape[1])):\n",
        "        plt.text(j, i, format(plt_cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if plt_cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predict')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PuMtsloj227g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# apply conversion function to data\n",
        "y_test_ind = convert_to_index(y_test)\n",
        "y_pred_test_ind = convert_to_index(y_pred_test)\n",
        "\n",
        "# compute confusion matrix\n",
        "cm_test = ConfusionMatrix(y_test_ind, y_pred_test_ind)\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# plot confusion matrix result\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cm_test,title='cm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T36Y07WjN2ea",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "*Things to think about and notice:*\n",
        "\n",
        "1. How does this confusion matrix compare to that from the Dense network?"
      ]
    },
    {
      "metadata": {
        "id": "Zu8T1uCEakHJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Problems for the CNNs (I mean ones that Wolf Blitzer can't solve)"
      ]
    },
    {
      "metadata": {
        "id": "MmlBFVNS_XVm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Problem 1: There are a lot of moving parts here. A lot of in's and out's\n",
        "(bonus points if you know the 2000's movie, from which this is a near-quote.)\n",
        "\n",
        "So, let's reduce the data set size at the beginning of the notebook.\n",
        "\n",
        "For the rest of the exercises, we'd like to have the flexibility to experiment with larger networks (MOAR PARAMETERS, MOAR), so let's reduce the data set size. \n",
        "\n",
        "1. Go to the [cell where we download the data](https://colab.research.google.com/drive/1wKzhJ0cOsJbgM9L0uIVUCYW1f2Zdf3PK#scrollTo=qwXuui6_yYBv&line=2&uniqifier=1), and add a cell after it. \n",
        "2. Use array indexing and slicing to create a smaller training set. How about 5000? \n",
        "3. When train the model then, we'll want to update that validation fraction so that we get about 3000 in our training set."
      ]
    },
    {
      "metadata": {
        "id": "ErkWPb0uBkTF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Problem 2: Keeeep Learning! \n",
        "\n",
        "\n",
        "What happens if you run the cell that does the model-fitting again, right after doing it the first time. What do you notice about the loss and accuracy, as compared to when you did the fitting the first time?\n",
        "\n",
        "Why do you think this is happening? \n"
      ]
    },
    {
      "metadata": {
        "id": "OYry9LJ2HaLV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Problem 3: What happens if you add a maxpooling layer? \n",
        "\n",
        "Does this change the training speed? \n",
        "Why might this be? \n",
        "Check the model summary output to see what effect the pooling layer has."
      ]
    },
    {
      "metadata": {
        "id": "423qaUg-Fnr7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Problem 4: How deep can you make the network? \n",
        "\n",
        "1. Make a deep network and see how many parameters you can make. Is it trainable in a reasonable amount of time? Try add Conv layers, but not pooling layers.\n",
        "2. What if you want it to be efficient? Try adding a Max Pooling Layers after every Conv layer. How many layers can you possibly add now? Compile the model until you have an output shape of ( None, 1, 1 , #PARAMS) before the first dense layer."
      ]
    },
    {
      "metadata": {
        "id": "sU6AzZ4z_Oe3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Problem 5: Comparing performance and efficiency between CNNs and Dense Networks\n",
        "\n",
        "Experiment with the neural network above, and reduce the number of parameters to near that of the Dense network in the first exercise. \n",
        "\n",
        "Is there a CNN architecture that has the same number of parameters as the Dense network, but can perform better?\n",
        "\n",
        "Remember to think deeply, to pool your resources. When you're nearing the end it may not be as dense as it looks, but nearly so. \n"
      ]
    },
    {
      "metadata": {
        "id": "edCg5NRKd9Zw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Problem 6: What happens to the training result when you degrade the images?\n",
        "\n",
        "In this part, we will degrade the images by adding noise, and then by blurring the images, and we'll look at how the network training responds. \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "PPJ4iYNY1qUb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "###  Problem 7: Let's see if we can look inside the neural networks\n",
        "\n",
        "Using the [FAQ from Keras](https://keras.io/getting-started/faq/#how-can-i-obtain-the-output-of-an-intermediate-layer) or any other online resource, like examples from Github, can we make a plot of the feature maps for any of the layers, so we can see what the neural net sees?\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "5LjWQUZa8YEo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Problem 8: Let's progress to Regression.\n",
        "\n",
        "Consider the labels as real values and modify the network to perform regression instead of classification on those values. You may want to consider the following:\n",
        "* normalizing the labels.\n",
        "* normalizing the image data.\n",
        "* modifying the activations that are used.\n",
        "* modifying the loss function that is appropriate for real-valued prediction. (see [keras loss](https://keras.io/losses/) )"
      ]
    },
    {
      "metadata": {
        "id": "qwubzWGWWD6E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Activity 2: Compress Handwritten Digits with a Convolutional Autoencoder (CAE)\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "M1vvRDNUPPvM"
      },
      "cell_type": "markdown",
      "source": [
        "#### Add layers to the model sequentially [NEW]"
      ]
    },
    {
      "metadata": {
        "id": "3RlQQ6_DOppC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "autoencoder = Sequential()\n",
        "\n",
        "# Encoder Layers\n",
        "autoencoder.add(Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=x_train.shape[1:]))\n",
        "autoencoder.add(MaxPooling2D((2, 2), padding='same'))\n",
        "autoencoder.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
        "autoencoder.add(MaxPooling2D((2, 2), padding='same'))\n",
        "autoencoder.add(Conv2D(8, (3, 3), strides=(2,2), activation='relu', padding='same'))\n",
        "autoencoder.add(MaxPooling2D((2, 2), padding='same'))\n",
        "autoencoder.add(Conv2D(8, (3, 3), strides=(2,2), activation='relu', padding='same'))\n",
        "autoencoder.add(MaxPooling2D((2, 2), padding='same'))\n",
        "\n",
        "# Flatten encoding for visualization\n",
        "autoencoder.add(Flatten())\n",
        "autoencoder.add(Reshape((1, 1, 8)))\n",
        "\n",
        "# Decoder Layers\n",
        "autoencoder.add(UpSampling2D((2, 2)))\n",
        "autoencoder.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
        "autoencoder.add(UpSampling2D((2, 2)))\n",
        "autoencoder.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
        "autoencoder.add(UpSampling2D((2, 2)))\n",
        "autoencoder.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
        "autoencoder.add(UpSampling2D((2, 2)))\n",
        "autoencoder.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "autoencoder.add(UpSampling2D((2, 2)))\n",
        "autoencoder.add(Conv2D(1, (3, 3), activation='sigmoid', padding='same'))\n",
        "\n",
        "autoencoder.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "8BkzQgcSPQvY"
      },
      "cell_type": "markdown",
      "source": [
        "#### Create a separate model that is just the encoder\n",
        "\n",
        "This will allow us to encode the images and look at what the encoding results in. "
      ]
    },
    {
      "metadata": {
        "id": "vZsdGuKnOsjg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoder = Model(inputs=autoencoder.input, outputs=autoencoder.get_layer('flatten_8').output)\n",
        "encoder.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "y8aQZJTyPRNf"
      },
      "cell_type": "markdown",
      "source": [
        "#### Compile the autencoder"
      ]
    },
    {
      "metadata": {
        "id": "BurOIL3wO40_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "num_epochs = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "zi8VFHVfPRwm"
      },
      "cell_type": "markdown",
      "source": [
        "#### Plot the input, output, and encoded images"
      ]
    },
    {
      "metadata": {
        "id": "Xz2ygdxiO5rD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# set number of images to visualize\n",
        "num_images = 10\n",
        "\n",
        "# select random subsect to visualize\n",
        "np.random.seed(42)\n",
        "random_test_images = np.random.randint(x_test.shape[0], size=num_images)\n",
        "\n",
        "# encode images\n",
        "encoded_imgs = encoder.predict(x_test)\n",
        "\n",
        "#decode encode AND decode images\n",
        "decoded_imgs = autoencoder.predict(x_test)\n",
        "\n",
        "\n",
        "# plot figure\n",
        "plt.figure(figsize=(18, 4))\n",
        "\n",
        "num_rows=4\n",
        "num_pixel_x = 2\n",
        "num_pixel_y = 4\n",
        "\n",
        "for i, image_idx in enumerate(random_test_images):\n",
        "    # plot original image\n",
        "    ax = plt.subplot(4, num_images, i + 1)\n",
        "    plt.imshow(x_test[image_idx].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    \n",
        "    # plot encoded image\n",
        "    ax = plt.subplot(num_rows, num_images, num_images + i + 1)\n",
        "\n",
        "    plt.imshow(encoded_imgs[image_idx].reshape(num_pixel_x, num_pixel_y), interpolation=None, resample=None)\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    \n",
        "    # plot reconstructed image\n",
        "    ax = plt.subplot(num_rows, num_images, 2*num_images + i + 1)\n",
        "    plt.imshow(decoded_imgs[image_idx].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}